{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cfc6399d-4963-4269-ab6e-a435bcac84b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "!export PYTORCH_CUDA_ALLOC_CONF=\"expandable_segments:True\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8a089454-d5f0-41d7-98c9-768de0f9ff90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd9a860adef34363918e9b5efe6a66c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# import torch\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from datasets import load_dataset\n",
    "import json\n",
    "from peft import LoraConfig, get_peft_model\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForCausalLM,\n",
    "    Trainer,\n",
    "    TrainingArguments\n",
    ")\n",
    "\n",
    "model_name = \"Qwen/Qwen3-4B\"\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    torch_dtype=torch.bfloat16,  # bf16\n",
    "    # attn_implementation=\"flash_attention_2\",\n",
    "    device_map=\"auto\",\n",
    ")\n",
    "\n",
    "model.config.use_cache = False\n",
    "model.config.pretraining_tp = 1\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True, use_fast=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "db2dd334-0ba2-459e-ae9e-851e40e94515",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fri May 30 09:06:49 2025       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 570.133.07             Driver Version: 570.133.07     CUDA Version: 12.8     |\n",
      "|-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  NVIDIA GeForce RTX 5090        Off |   00000000:01:00.0 Off |                  N/A |\n",
      "|  0%   36C    P1             66W /  575W |    8924MiB /  32607MiB |      0%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "                                                                                         \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI              PID   Type   Process name                        GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "|    0   N/A  N/A           13465      C   ...gor/grammar/.venv/bin/python3       8914MiB |\n",
      "+-----------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "99ea4037-dd45-4d2a-8398-5186cbfc9156",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "ds = load_dataset(\"dair-ai/emotion\", \"split\", split=\"train[0:300]\")\n",
    "\n",
    "# ds => {text: str, label: int}\n",
    "\n",
    "# sadness (0), joy (1), love (2), anger (3), fear (4), surprise (5).\n",
    "str2int = {\n",
    "    \"sadness\": 0,\n",
    "    \"joy\": 1,\n",
    "    \"love\": 2,\n",
    "    \"anger\": 3,\n",
    "    \"fear\": 4,\n",
    "    \"surprise\": 5,\n",
    "}\n",
    "int2str = {v: k for k, v in str2int.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4d6361ee-0d10-488c-a70a-6fd197e4d693",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['text', 'label'],\n",
       "    num_rows: 300\n",
       "})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "53029131-da51-4c22-898f-7b250e3f2478",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "SYSTEM = \"\"\"\n",
    "You are an emotion classifier engineer.\n",
    "The classier itself works based on keywords and keyphrases.\n",
    "Your task as engineer is to populate each emotion with such keys and phrases that will precisely identify emotions in text.\n",
    "Here is the full list of emotions:\n",
    "- sadness\n",
    "- joy\n",
    "- love\n",
    "- anger\n",
    "- fear\n",
    "- surprise\n",
    "Your will be given a text, your must yield emotion name and keywords/keyphrases as such, if tool will use this keywords/keyphrases \n",
    "it will successfully classify the text into correct emotion\n",
    "Return in the format:\n",
    "\n",
    "```\n",
    "{\n",
    "\"emotion\": \"emotion name from the list\",\n",
    "\"keys\": [\"key1\", \"key2\"]\n",
    "}\n",
    "```\n",
    "Strictly adhere to the format\n",
    "\"\"\"\n",
    "\n",
    "def process_answer(completion: str):\n",
    "    try:\n",
    "        completion = completion.replace(\"```json\", \"\").replace(\"```\", \"\").strip()\n",
    "        completion = json.loads(completion)\n",
    "        emotion = completion[\"emotion\"] \n",
    "        keys = completion[\"keys\"]\n",
    "        return emotion, keys\n",
    "    except Exception as e:\n",
    "        return \"\", []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "02e2573d-1ae0-4034-8a4a-1ff07073f056",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f795c7b195fc4f8e9ed6904de4ec7eeb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/300 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['prompt', 'labels'],\n",
       "    num_rows: 300\n",
       "})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def preprocess(example):\n",
    "    texts = example[\"text\"]\n",
    "    labels = example[\"label\"]\n",
    "    data = {\"prompt\": [], \"labels\": []}\n",
    "    for text, label in zip(texts, labels):\n",
    "\n",
    "        data[\"prompt\"].append(\n",
    "           tokenizer.apply_chat_template([\n",
    "                {\"role\": \"system\", \"content\": SYSTEM},\n",
    "                {\"role\": \"user\", \"content\": text}\n",
    "            ], tokenize=False, add_generation_prompt=True, enable_thinking=True), \n",
    "        )\n",
    "        data[\"labels\"].append(int2str[label])\n",
    "    \n",
    "    return data\n",
    "\n",
    "\n",
    "transformed_dataset = ds.map(preprocess, batched=True, remove_columns=ds.column_names)\n",
    "transformed_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f8e69510-4617-4fa2-b393-067578accfe3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'prompt': '<|im_start|>system\\n\\nYou are an emotion classifier engineer.\\nThe classier itself works based on keywords and keyphrases.\\nYour task as engineer is to populate each emotion with such keys and phrases that will precisely identify emotions in text.\\nHere is the full list of emotions:\\n- sadness\\n- joy\\n- love\\n- anger\\n- fear\\n- surprise\\nYour will be given a text, your must yield emotion name and keywords/keyphrases as such, if tool will use this keywords/keyphrases \\nit will successfully classify the text into correct emotion\\nReturn in the format:\\n\\n```\\n{\\n\"emotion\": \"emotion name from the list\",\\n\"keys\": [\"key1\", \"key2\"]\\n}\\n```\\nStrictly adhere to the format\\n<|im_end|>\\n<|im_start|>user\\ni didnt feel humiliated<|im_end|>\\n<|im_start|>assistant\\n',\n",
       " 'labels': 'sadness'}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformed_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd13182b-f1a1-4092-9158-a0e6d32d8b87",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9dfca8c7-f51c-421c-b9c7-ea6a91ba63f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lark import Lark, Token\n",
    "from lark import UnexpectedToken, UnexpectedCharacters\n",
    "from lark.lexer import PatternRE, PatternStr\n",
    "from lark.reconstruct import Reconstructor\n",
    "from lark.parsers.lalr_interactive_parser import InteractiveParser\n",
    "from lark import GrammarError\n",
    "from typing import Union, Callable, Optional\n",
    "\n",
    "\n",
    "def is_pattern_regex(pattern: Union[PatternRE, PatternStr]):\n",
    "        return isinstance(pattern, PatternRE)\n",
    "    \n",
    "def is_pattern_string(pattern: Union[PatternRE, PatternStr]):\n",
    "    return isinstance(pattern, PatternStr)\n",
    "\n",
    "\n",
    "class Rebuilder:\n",
    "\n",
    "    def __init__(self, \n",
    "                 grammar: str, \n",
    "                 term_subs: dict[str, str] = None,\n",
    "                 token_transformer: Callable[[str, str, bool], str] = None,\n",
    "                 ):\n",
    "        \"\"\"\n",
    "        term_subs: dict[str, str] = None, -> term subs when reconstructing grammar from ast\n",
    "        token_transformer: Callable[[str, str, bool], str] = None, -> token_name, inputs string and is_regex flag, returns token defs\n",
    "        \"\"\"\n",
    "        self.grammar = grammar\n",
    "        self.parser = Lark(grammar, \n",
    "                           parser=\"lalr\", \n",
    "                           start=\"start\", \n",
    "                           strict=False, \n",
    "                           lexer=\"contextual\", \n",
    "                           maybe_placeholders=False,\n",
    "                           regex=True\n",
    "                           )\n",
    "        self.terminals = self.parser.lexer_conf.terminals_by_name\n",
    "        self.reconstructor = Reconstructor(self.parser, term_subs) \\\n",
    "                                if term_subs else Reconstructor(self.parser)\n",
    "        self.token_transformer = token_transformer if token_transformer else None\n",
    "    \n",
    "    def get_token_definition(self, token: str):\n",
    "        pattern = self.terminals.get(token, None)\n",
    "        if pattern is not None:\n",
    "            return pattern.pattern\n",
    "        return None\n",
    "    \n",
    "    def as_token(self, token: str) -> Token:\n",
    "        tok_def = self.get_token_definition(token)\n",
    "        if self.token_transformer:\n",
    "            tok_def = self.token_transformer(token, tok_def, is_pattern_regex(tok_def))\n",
    "        if tok_def is None:\n",
    "            tok_def = token\n",
    "        return Token(token, tok_def)\n",
    "    \n",
    "    def beam_search(self, \n",
    "                    parser: InteractiveParser, \n",
    "                    given_token: Token, \n",
    "                    beam_width: int = 10, \n",
    "                    strategy: str = \"shortest\", # longest\n",
    "                    break_early_limit: Optional[int] = 3,\n",
    "                    ) -> list[Token]:\n",
    "        \"\"\"\n",
    "        strategy: \"shortest\" or \"longest\"\n",
    "        break_early_limit: \n",
    "        if strategy is \"shortest\", break early as soon as one of any path \n",
    "        that consist no more than break_early_limit tokens is found, priorisizing the shortest path\n",
    "        if strategy is \"longest\", break early as soon as lenght of tokens path is at least break_early_limit,\n",
    "        priorisizing the longest path\n",
    "        \"\"\"\n",
    "        assert strategy in [\"shortest\", \"longest\"], \"strategy must be either 'shortest' or 'longest'\"\n",
    "        if break_early_limit is not None:\n",
    "            assert break_early_limit <= beam_width, \"break_early_limit must be less than or equal to beam_width\"\n",
    "        if beam_width <= 0:\n",
    "            return []\n",
    "        candidates = {} # token2shortest_path\n",
    "        candidates_score = {} # score2token\n",
    "        accepted_tokens = list(parser.accepts()) # returns list of token names\n",
    "        accepted_tokens.sort(key=lambda x: int(is_pattern_string(x)), reverse=False) # first -> string, then -> regex\n",
    "        for token in accepted_tokens:\n",
    "            dummy_parser = parser.copy()\n",
    "            token = self.as_token(token)\n",
    "            try:\n",
    "                dummy_parser.feed_token(token)\n",
    "                success = False\n",
    "                # for the first two cases let's assume that there are missing tokens between tokena and given token\n",
    "                if given_token.type in dummy_parser.accepts():\n",
    "                    # case 1: some token is missing\n",
    "                    candidates[token] = [token, given_token]\n",
    "                    candidates_score[1] = token\n",
    "                    success = True\n",
    "                else:\n",
    "                    # case 2: a series of tokens are missing\n",
    "                    res = [token] + self.beam_search(\n",
    "                        parser=dummy_parser, \n",
    "                        given_token=given_token, \n",
    "                        beam_width=beam_width-1,\n",
    "                        strategy=strategy,\n",
    "                        break_early_limit=None\n",
    "                    )\n",
    "                    score = len(res)\n",
    "                    candidates[token] = res\n",
    "                    candidates_score[score] = token\n",
    "                    success = len(res) > 1\n",
    "                if not success:\n",
    "                    # if our hypothesis is wrong (no path discovered), then simply chose the correct token and ignore given token\n",
    "                    # case 3: given token is not needed at all, remove given token from path\n",
    "                    candidates[token] = [token]\n",
    "                    candidates_score[0] = token\n",
    "            except GrammarError as e:\n",
    "                raise e\n",
    "\n",
    "            if break_early_limit is None:\n",
    "                continue\n",
    "            if strategy == \"shortest\":\n",
    "                for i in range(break_early_limit):\n",
    "                    if i in candidates_score:\n",
    "                        return candidates[candidates_score[i]] # break early\n",
    "            elif strategy == \"longest\":\n",
    "                for i in range(beam_width, break_early_limit, -1):\n",
    "                    if i in candidates_score:\n",
    "                        return candidates[candidates_score[i]] # break early\n",
    "\n",
    "        if not candidates:\n",
    "            return []\n",
    "        if strategy == \"shortest\":\n",
    "            best_score = min(candidates_score.keys()) # the shortest path\n",
    "        elif strategy == \"longest\":\n",
    "            best_score = max(candidates_score.keys()) # the longest path\n",
    "        return candidates[candidates_score[best_score]]\n",
    "    \n",
    "    def repair(self, text: str, beam_width: int = 10, strategy: str = \"shortest\", break_early_limit: Optional[int] = 3):\n",
    "        def _repair(e):\n",
    "            if isinstance(e, UnexpectedToken):\n",
    "                path = self.beam_search(e.interactive_parser, e.token, beam_width, strategy, break_early_limit)\n",
    "                if not path:\n",
    "                    raise e\n",
    "                for token in path:\n",
    "                    if token.type != \"$END\":\n",
    "                        e.interactive_parser.feed_token(token)\n",
    "                return True\n",
    "            elif isinstance(e, UnexpectedCharacters):\n",
    "                return True # simply ignore\n",
    "            else:\n",
    "                raise e\n",
    "        \n",
    "        tree = self.parser.parse(text, on_error=_repair)\n",
    "        return self.reconstructor.reconstruct(tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bc836be8-38ed-40e4-8821-fda5fadd0c7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# gnosis\n",
    "\n",
    "from typing import List, Dict, Callable, Optional\n",
    "\n",
    "# from rebuilder import Rebuilder\n",
    "from dataclasses import dataclass\n",
    "from abc import ABC, abstractmethod\n",
    "\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class BaseTerminal(ABC):\n",
    "    name: str\n",
    "    \n",
    "    def __post_init__(self):\n",
    "        assert self.name.upper() == self.name, \"name must be uppercase\"\n",
    "\n",
    "    @property\n",
    "    @abstractmethod\n",
    "    def as_terminal(self) -> str:\n",
    "        pass\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class Class(BaseTerminal):\n",
    "    name: str\n",
    "    values: List[str] # a list of keywords/keyphrases\n",
    "    fuzzy_temperature: float = 0.5\n",
    "\n",
    "    def __post_init__(self):\n",
    "        assert self.fuzzy_temperature >= 0. and self.fuzzy_temperature <= 1., \"fuzzy_temperature must be between 0 and 1\"\n",
    "        super().__post_init__()\n",
    "\n",
    "    def __calculate_fuzzy_temperature(self, value: str):\n",
    "        return max(0, int(len(value) * self.fuzzy_temperature - 1))\n",
    "\n",
    "    @property\n",
    "    def as_terminal(self):\n",
    "        _values = []\n",
    "        for value in self.values:\n",
    "            temp = self.__calculate_fuzzy_temperature(value)\n",
    "            fuzzy_postfix = \"\"\n",
    "            if temp > 0:\n",
    "                fuzzy_postfix = \"{\" + f\"e<={temp}\" + \"}\"\n",
    "            value = f\"(?:{value}){fuzzy_postfix}\"\n",
    "            _values.append(value)\n",
    "        return f\"{self.name}: /{'|'.join(_values)}/i\"\n",
    "\n",
    "\n",
    "class Gnosis:\n",
    "\n",
    "\n",
    "    @staticmethod\n",
    "    def setup_grammar(start: str, schema: str, terminals: List[BaseTerminal]):\n",
    "        _terminals = \"\\n\".join([terminal.as_terminal for terminal in terminals])\n",
    "        return f\"\"\"\n",
    "start: {start}\n",
    "{schema}\n",
    "{_terminals}\n",
    "\"\"\"\n",
    "\n",
    "    def __init__(self, \n",
    "                 start: str, \n",
    "                 schema: str, \n",
    "                 terminals: List[BaseTerminal],\n",
    "                 term_subs: Optional[Dict[str, str]] = None,\n",
    "                 token_transformer: Optional[Callable[[str, str, bool], str]] = None):\n",
    "        # in theory, terminls must be anything that transform something into terminal def\n",
    "        self.__start = start\n",
    "        self.__schema = schema\n",
    "        self.terminals = terminals\n",
    "        self.__grammar = self.__class__.setup_grammar(start, schema, terminals)\n",
    "        self.__rebuilder = Rebuilder(\n",
    "            grammar=self.__grammar, \n",
    "            term_subs=term_subs, \n",
    "            token_transformer=token_transformer)\n",
    "    \n",
    "    # @property\n",
    "    # def terminals(self):\n",
    "    #     return self.__terminals\n",
    "\n",
    "    @property\n",
    "    def start(self):\n",
    "        return self.__start\n",
    "    \n",
    "    @property\n",
    "    def schema(self):\n",
    "        return self.__schema\n",
    "    \n",
    "    @property\n",
    "    def grammar(self):\n",
    "        self.__grammar = self.__class__.setup_grammar(self.start, self.schema, self.terminals)\n",
    "        return self.__grammar\n",
    "    \n",
    "    def repair(self, input_: str, *args, **kwargs):\n",
    "        return self.__rebuilder.repair(input_, *args, **kwargs)\n",
    "\n",
    "\n",
    "\n",
    "class Classifier(Gnosis):\n",
    "\n",
    "    SEPARATOR = \">>\"\n",
    "    MISSING_CLASS = \"MISSING_CLASS\"\n",
    "\n",
    "    @staticmethod\n",
    "    def missing_class(token_name: str, token_def: str, is_regex: bool):\n",
    "        if is_regex:\n",
    "            return Classifier.MISSING_CLASS\n",
    "        else:\n",
    "            return token_def\n",
    "    \n",
    "\n",
    "    @staticmethod\n",
    "    def conditional_rule(name: str):\n",
    "        return f'{name} \"{Classifier.SEPARATOR}\" \"{name.lower()}\"'\n",
    "\n",
    "    def __init__(self, classes: List[Class]):\n",
    "        super().__init__(\n",
    "            start=\"class\",\n",
    "            schema=f\"class: {' | '.join([self.__class__.conditional_rule(class_.name) for class_ in classes])}\",\n",
    "            terminals=classes,\n",
    "            token_transformer=self.__class__.missing_class)\n",
    "    \n",
    "    \n",
    "    def update(self, class_name, classes: list):\n",
    "        for cls in self.terminals:\n",
    "            if cls.name == class_name.upper():\n",
    "                cls.values += classes\n",
    "    \n",
    "    def repair(self, input_: str, *args, **kwargs):\n",
    "        result = super().repair(input_, *args, **kwargs)\n",
    "        input_, output = result.split(Classifier.SEPARATOR)\n",
    "        if input_ == Classifier.MISSING_CLASS:\n",
    "            return Classifier.MISSING_CLASS\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ae909f36-f6b5-416b-8295-751dd8f5a643",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = classifier = Classifier([\n",
    "    Class(name=\"SADNESS\", values=[\"sad\"]),\n",
    "    Class(name=\"JOY\", values=[\"joy\"]),\n",
    "    Class(name=\"LOVE\", values=[\"love\"]),\n",
    "    Class(name=\"ANGER\", values=[\"angry\"]),\n",
    "    Class(name=\"FEAR\", values=[\"fear\"]),\n",
    "    Class(name=\"SURPRISE\", values=[\"surprise\"]),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efec4485-c025-4597-b201-b32da63fb12b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "18d49da7-c424-4238-b94c-0666a3ac2551",
   "metadata": {},
   "outputs": [],
   "source": [
    "def llm_accuracy_reward(completions, **kwargs):\n",
    "    rewards = []\n",
    "    for n, completion in enumerate(completions):\n",
    "        reward = 0.0\n",
    "        expected_label = kwargs[\"labels\"][n].strip()\n",
    "        completion = completion.split(\"</think>\")[-1]\n",
    "        predicted_label, _ = process_answer(completion)\n",
    "        if expected_label == predicted_label.strip():\n",
    "            reward += 1.0\n",
    "        rewards.append(reward)\n",
    "    return rewards\n",
    "\n",
    "\n",
    "def tool_accuracy_reward(completions, **kwargs):\n",
    "    rewards = []\n",
    "    for n, completion in enumerate(completions):\n",
    "        reward = 0.0\n",
    "        expected_label = kwargs[\"labels\"][n].strip()\n",
    "        completion = completion.split(\"</think>\")[-1]\n",
    "        predicted_label = classifier.repair(completion).strip()\n",
    "        if expected_label == predicted_label:\n",
    "            reward += 1.0\n",
    "        else:\n",
    "            emotion, classes = process_answer(completion)\n",
    "            if classes:\n",
    "                classifier.update(emotion, classes)\n",
    "                predicted_label = classifier.repair(completion)\n",
    "            # if expected_label == predicted_label:\n",
    "            #     reward += 0.5\n",
    "        rewards.append(reward)\n",
    "    return rewards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "63d94246-6bf6-44a6-9f0b-611a83604803",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 16,515,072 || all params: 4,038,983,168 || trainable%: 0.4089\n"
     ]
    }
   ],
   "source": [
    "from peft import get_peft_model, LoraConfig, TaskType\n",
    "\n",
    "lora_config = LoraConfig(\n",
    "    task_type=TaskType.CAUSAL_LM,  \n",
    "    r=8,\n",
    "    lora_alpha=32,\n",
    "    lora_dropout=0.05,\n",
    "    target_modules=[\"q_proj\", \"v_proj\", \"k_proj\", \"v_proj\", \"o_proj\", \"gate_proj\", \"up_proj\", \"down_proj\",]  \n",
    ")\n",
    "\n",
    "peft_model = get_peft_model(model, lora_config)\n",
    "peft_model.print_trainable_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "31141177-640a-449b-bca8-d9148550b8d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from trl import GRPOConfig\n",
    "\n",
    "# Configure training arguments using GRPOConfig\n",
    "training_args = GRPOConfig(\n",
    "    output_dir=\"Qwen4B-Grammar-RL-CLS\",\n",
    "    overwrite_output_dir=True,\n",
    "    prediction_loss_only=True,\n",
    "    optim=\"paged_adamw_32bit\",\n",
    "    lr_scheduler_type=\"cosine\",\n",
    "    learning_rate=1e-5,\n",
    "    remove_unused_columns=False,  # to access the solution column in accuracy_reward\n",
    "    per_device_train_batch_size=1,\n",
    "    gradient_accumulation_steps=4,\n",
    "    num_train_epochs=1,\n",
    "    bf16=True,\n",
    "    # Parameters that control de data preprocessing\n",
    "    max_completion_length=512*3,  # default: 256\n",
    "    num_generations=4,  # default: 8\n",
    "    max_prompt_length=512,  # default: 512\n",
    "    # Parameters related to reporting and saving\n",
    "    report_to=\"mlflow\", # https://huggingface.co/docs/transformers/main_classes/callback\n",
    "    log_completions=True,\n",
    "    group_by_length=True,\n",
    "    # logging_steps=0.1,\n",
    "    logging_steps=15,\n",
    "    push_to_hub=False,\n",
    "    save_strategy=\"steps\",\n",
    "    save_steps=50,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "85d20540-21d3-4095-b2a0-716a3aa8a69d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n"
     ]
    }
   ],
   "source": [
    "from trl import GRPOTrainer\n",
    "\n",
    "trainer = GRPOTrainer(\n",
    "    model=peft_model, \n",
    "    reward_funcs=[llm_accuracy_reward, tool_accuracy_reward], \n",
    "    args=training_args, \n",
    "    train_dataset=transformed_dataset\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c8f68ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc, torch\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "model.config.use_cache = False\n",
    "\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2a6d25d7-87db-46ba-b3c9-bb844897cfee",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.save_model(\"Qwen4B-Grammar-RL-CLS\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b911aff3-c6cc-4a81-8a1e-fcd1d217f9d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "data = {}\n",
    "for term in classifier.terminals:\n",
    "    data[term.name] = term.values\n",
    "\n",
    "\n",
    "with open(\"classifier.json\", \"w\") as f:\n",
    "    json.dump(data, f, indent=2, ensure_ascii=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8affd63b-99f8-4954-8c96-a67bb3111ea1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
